\chapter{Evaluation in case of data sets from financial market model\label{cha:chapter6}}

We only present the comparison between HNNs and LSTM networks in this chapter since SimpleRNN and GRU's performance is similar to LSTM's .
\section{Synthetic data sets from financial market model}\label{sec:chapter5:synthetic-data-sets}
Following the practical approach described in     \mysectionref{sec:chapter3:practical-approches}, we obtain the synthetic data sets (see \myfigref{fig:chapter5:market-ground-truth-dataset}) below. We only display the figures whose standard deviation of $b_n - b_{n-1}$ is 20 since the standard deviation 10 is similar to it. \myupdate{We use the first 1300 points for training set and the rest 400 points for test set.}
\begin{figure}[h!]
    \centering
    \subfloat[]{
        \includegraphics[height=7cm,width=\textwidth]{market-ground-truth-dataset}
    }
    \caption[The synthetic data sets generated from the financial market model.]{The synthetic data sets generated from the financial market model. The standard deviation of the difference of the random walk $b_n - b_{n-1}$ is 20. The top one is the random walk, which is underline in the real market, of the simulation. The middle one is the fluctuation of the prices based on the model. And the bottom one the change of the total number of stocks in the market, which is following to random walk.}
    \label{fig:chapter5:market-ground-truth-dataset}
\end{figure}
\newline
\section{Setup}
In the financial market model, we evaluate the LSTM networks with units 64, 128, and 256, and select the best performance. In this thesis, LSTM networks with 64 units \myupdate{outperform} the rest models. As for HNN, we utilize 50 \textit{\_\_plays\_\_} and 50 \textit{\_\_units\_\_} to train the network. All these networks are trained with \myupdate{10000} epochs. For RMSE, we evaluate $d_n = |b_n - b_{n-1}|$ instead of $b_n$ directly since the sequence $\mathcal{B}_n = \{b_0, b_1, \ldots, b_n\}$ is unobservable to us (see \mysectionref{sec:chapter4:assumption}). To make it clear, we rewrite RMSE as follows,
\begin{eqnarray*}
    \text{RMSE} &= \sqrt{\frac{\sum_{i=1}^{N}(\hat{d}_i - d_i)^2}{N}} \\
    s.t. & \hat{d}_i = \hat{b}_i - \hat{b}_{i-1} \\
    & d_i = b_i - b_{i-1}
\end{eqnarray*}
where $b_i$ is the underline ground-truth noise (extracted from financial market model) and $\hat{b}_i$ is the underline predictive noise (reconstructed by HNN).

\section{Results and analysis}
\mytableref{tbl:chapter5:simulation-stock-results} presents the different performance between LSTM networks and HNN. The data set with $\sigma=20$ means $d_n$ is followed to normal distribution $\mathcal{N}(0, 20)$. We see that HNN outperforms LSTM networks dramatically. HNN can recover the mean $\mu$ and standard deviation $\sigma$ from the random walk accurately, and the results are much more \myupdate{robust} than that learned by LSTM networks \myupdate{comparing the standard deviation of RMSE}. Meanwhile, it reveals that HNN utilizes fewer parameters to produce better RMSE than LSTM.
\myfigref{fig:chapter5:lstm-hnn-stock-mle} shows the curve of $d_n$ generated by LSTM networks and HNN.
We notice that the standard deviation obtained by LSTM networks is underrated, and \mytableref{tbl:chapter5:simulation-stock-results} confirms this circumstance associated with the average of standard deviation being around 15.24. Unlike the predicted curve produced by HNN overlapping with the ground-truth one, the blue curve generated by LSTM networks diverges from the ground-truth results and has a smaller magnitude spreading most time steps. 
\myfigref{fig:chapter6:market-lstm-result,fig:chapter6:market-hnn-result} present that HNN traces the ground-truth random walk better than LSTM networks do. In  \myfigref{fig:chapter6:market-lstm-result,fig:chapter6:market-hnn-result}, the scale of their outputs are not the same since both HNN and LSTM networks do not learn the standard deviation precisely. One analyzes the prices on test set and $d_n$ is mostly interesting since it tells the trend of the future price. We present a more detailed comparison of random walk generated by HNN and LSTM networks in \myappendixsectionref{appendix:comparsion-random-walk}.

\begin{table}[htb!]
\centering
\begin{adjustbox}{angle=0}
\begin{tabular}{||c|c|c|c|c|c||}
\hline 
 Data set & network & \#parameters & estimated $\mu$ & estimated $\sigma$ & RMSE  \\
\hline \hline
\multirow{2}{4em}{$\sigma=10$} & \multirow{1}{4em}{LSTM} & 16961 & 0.05 $\pm$ 0.20 & 5.55 $\pm$ 1.98 & 10.05 $\pm$ 1.39 \\ 
                          \cline{2-6}
                          & \multirow{1}{4em}{HNN}  & 7501 & -0.25  $\pm$ 0.44 & 12.22 $\pm$ 0.38 & 7.40 $\pm$ 0.84 \\ 
                          \cline{2-6}
\hline

\multirow{2}{4em}{$\sigma=20$} & \multirow{1}{4em}{LSTM} & 16961 & 0.05 $\pm$ 0.20 & 15.24 $\pm$ $4.26$ & 18.36 $\pm$ 2.05 \\
                          \cline{2-6}
                          & \multirow{1}{4em}{HNN}  & 7501 & 0.09 $\pm$ 0.20 & 19.74 $\pm$ 0.42  & 8.82 $\pm$ 0.91 \\ 
                          \cline{2-6}
\hline


\end{tabular}
\end{adjustbox}
\caption{RMSE for simulation results on test set.} 
\label{tbl:chapter5:simulation-stock-results}
\end{table}


\begin{figure}[htb!]
    \centering
    \subfloat[LSTM]{
        \includegraphics[height=2.8cm,width=\textwidth]{thesis/img/lstm-stock-diff-outputs-units-64.pdf}
        \label{fig:chapter5:lstm-stock-mle}
    }
    \hfill
    \subfloat[HNN]{
        \includegraphics[height=2.8cm,width=\textwidth]{thesis/img/hnn-stock-diff-outputs.pdf}
        \label{fig:chapter5:hnn-stock-mle}
    }    
    \caption[Sequence of difference of $b_{n} - b_{n-1}$ on test set.]{Sequence of difference of $b_{n} - b_{n-1}$ on test set. The curve in red is ground-truth and the blue one is generated by trained networks.}
    \label{fig:chapter5:lstm-hnn-stock-mle}
\end{figure} 
%% TODO'
\begin{figure}[htb!]
    \centering
    \subfloat[LSTM]{
        \scalebox{1.0} {
        \includegraphics[height=2.8cm,width=\textwidth]
    % {img/market-prediction-lstm/6.pdf}
     {img/market-prediction-lstm/1.pdf}
        }
        \label{fig:chapter6:market-lstm-result}
    }
    \hfill
    \subfloat[HNN]{
        \scalebox{1.0} {
        \includegraphics[height=2.8cm,width=\textwidth]
        % {img/market-prediction-hnn/6.pdf}
         {img/market-prediction-hnn/1.pdf}
        }
        \label{fig:chapter6:market-hnn-result}
    }
    \caption[The predictive outputs against ground-truth outputs for LSTM and HNN.]{The predictive $\hat{b}_n$ against ground-truth $b_n$ on the test set. The red curve is ground-truth, and the blue one is generated by trained networks}
    \label{fig:chapter6:market-hnn-lstm-results}
\end{figure}


\FloatBarrier
% \textbf{Reconstructing \myupdate{aggregated} dynamics of agents.} 
\section{Reconstructing \myupdate{aggregated} dynamics of agents}
\myfigref{fig:chapter5:dynamics-of-agents} displays the dynamics of aggregated agents retrieved from the financial market model and HNN. 
The red dotted curve is the dynamics extracted from HNN, and one in orange and blue is the dynamics from the market model. The blue curve is the dynamics of agents taken place if external agents buy (sell) stocks in simulation. On the contrary, the orange one is that we want to inspect the dynamics if the external agents sell (buy) stocks at the same time step. \myupdate{The intersection of the blue and orange curve is the initial price at that time step.} We stress that the data in orange are not presented in the training set \myupdate{and we will see that HNN can reconstruct the orange curves properly without observing them in the training set}. \myfigref{fig:chapter5:dynamics-of-agents-1} indicates that HNN can thoroughly reconstruct the dynamics of aggregated agents from the training set. 
\myfigref{fig:chapter5:dynamics-of-agents-2} shows that the volume of aggregated agents decreases slightly, then increases. Similarly, the numeric quantity generated from HNN fits the trajectory. 
The orange curve in \myfigref{fig:chapter5:dynamics-of-agents-3} is unconscious to \myupdate{the HNN due to the absence in} training set. However, we observe the red curve produced by HNN reconstructs these dynamics correctly. It implies HNN not only inspects the training set but also restores \myupdate{the strategies of} the agents participated in the market.
Considering \myfigref{fig:chapter5:dynamics-of-agents-4}, we observe the blue curve decreases first, then increases, finally decreases. Meantime the trajectory obtained from HNN follows this tendency. 
Moreover, we can explain that the avalanche of the \myupdate{price} based on \myfigref{fig:chapter5:dynamics-of-agents-4}. We see there are black and red horizontal lines in \myfigref{fig:chapter5:dynamics-of-agents-4}. If the random walk decreases from -457 (the intersection of the orange and blue curve) to -570 (the black horizontal line), the price only increases from 0.008 to 0.056. However, if the next random walk is a bit lower than -570, take -590 (the red horizontal line), for example, we will observe that the price will rise to 0.165, which is triple times than the previous case. That illustrates why some small fluctuations of stocks lead to a large \myupdate{changes} in price. It coincides to the analysis in \myassumptionref{assumption:chapter3:transitions-between-stabilized-prices} and \myfigref{fig:chapter3:price-change-bifurcation-2}.

% Suppose that the change of stocks in market

% The difference between blue and orange curve is that the blue curve is the dynamics of external agents 

\begin{figure}[htb!]
    \centering
    \subfloat[]{
    \includegraphics[width=\textwidth/2]{thesis/img/inspect-agents-behaviours/29.pdf}
        \label{fig:chapter5:dynamics-of-agents-1}
    }
    \subfloat[]{
    \includegraphics[width=\textwidth/2]{thesis/img/inspect-agents-behaviours/31.pdf}
            \label{fig:chapter5:dynamics-of-agents-2}
    }
    \hfill
    \subfloat[]{
    \includegraphics[width=\textwidth/2]{thesis/img/inspect-agents-behaviours/15.pdf}
    \label{fig:chapter5:dynamics-of-agents-3}
    }
    \subfloat[]{
    \includegraphics[width=\textwidth/2]{thesis/img/inspect-agents-behaviours/53.pdf}
    \label{fig:chapter5:dynamics-of-agents-4}
    }    
    \caption[Dynamics of aggregated agents.]{Dynamics of aggregated agents \myupdate{corresponding to four different independent events} on the market on the test set. If the amount of stocks increases, it means the external agents sell stocks to the market, and the price drops. On the contrary, if the amount of stocks decreases, it indicates the external agents buy stocks from the market, and the price rises. 
    \myupdate{The blue curve (dynamics generated by \myupdate{actual scenario}) is the dynamics of aggregated agents that took place in the simulation. The orange one (dynamics generated by \myupdate{potential scenario}) is that we want to inspect what the dynamics would be if external agents take the opposite action at the same time steps, i.e., if the blue curve is resulted in by external agents buy the stocks from market, the orange curve is resulted in by the external agents sell the stock to market correspondingly.}}
    \label{fig:chapter5:dynamics-of-agents}
\end{figure}
\FloatBarrier


\section{Predicting price}
\textbf{Methods.} To distinguish difference predicting performance among different methods, we consider the following three approaches. The first approach is to predict the next price $\hat{p}_i$ the same as the previous price $p_{i-1}$, and we call it \textit{native method}. The second method is using LSTM networks described in \citep{kagglelstm}. The last one is using the methods described in \mysectionref{sec:chapter4:predicting_price}.  
 
\textbf{Measure.} To show the fine performance of the predictions, we divide \myupdate{price change} ${p_n-p_{n-1}}$ and \myupdate{noise jumps $b_n - b_{n-1}$} into $R \times R$ grids 
\mydelete{and generate the difference $|\hat{p}_i - p_i|$ at each}
slot $\text{SLOT}_j$ \myupdate{where}, 


\begin{equation}
\begin{aligned}
\text{SLOT}_j = \big\{ (\Delta p, \Delta b) : \Delta p_{j-1} < \Delta p \le \Delta p_j, \Delta b_{j-1} < \Delta b \le \Delta b_j \big\}
\end{aligned}
\end{equation}
and $\hat{p}_i$ is the predicted price, $p_i$ is the ground-truth price, $\Delta{p}_j = j \frac{\max\{p_1, p_2, \ldots\} - \min\{p_1, p_2, \ldots\}}{R}$, $\Delta{b}_j = j \frac{\max\{b_1, b_2, \ldots\} - \min\{b_1, b_2, \ldots\}}{R}$ and $j=0,1,\ldots$

Then the modified RMSE at 
$\text{SLOT}_j$ is given by,
\begin{equation}
\begin{aligned}
& & & \text{RMSE}(\text{SLOT}_j) = \sqrt{\frac{1}{C} \sum_{i} (\hat{p}_i - p_i)^2 }  \\
& \text{s.t.} & & (|p_i - p_{i-1}|, |b_i - b_{i-1}|) \in \text{SLOT}_j \\
& & & C = \text{card}(\text{SLOT}_j)
\end{aligned}
\end{equation}
\myupdate{With revised \text{RMSE}, we can easily explore how the noise jumps affects the predicted price accuracy.}

\textbf{Results.} \myfigref{fig:chapter5:predicting-price} shows the different RMSE for three methods mentioned above. 
Comparing \myfigref{fig:chapter5:predicting-price-baseline} and \myfigref{fig:chapter5:predicting-price-hnn}, we see that the RMSE are close to each other when $\Delta p < 0.059$. \myupdate{But} HNN performs better than the native methods when $\Delta p > 0.059$ (\myupdate{The RMSE of HNN and native approach are 0.082 and 0.097 respectively}). It indicates HNN can predict the dramatic fluctuation of the price, whereas the native approach cannot.
We observe that the results generated by HNN have smaller RMSE among most slots in \myfigref{fig:chapter5:predicting-price-lstm,fig:chapter5:predicting-price-hnn}. As for $\Delta p >= 0.059$, LSTM exceeds HNN if we only consider RMSE. However, when we inspect the predicted price obtained by HNN and LSTM, we find that HNN gives us an insight for the avalanche of the price (see \myfigref{fig:chapter5:predicting-price,fig:chapter5:price-predictions,fig:chapter5:predicting-price-2}). Briefly explanation, we see there might be an avalanche from \myfigref{fig:chapter5:predicting-price-156} if external agents sell stocks to the market. \myupdate{And in the consecutive time steps, we observe circumstance during the simulation in \myfigref{fig:chapter5:predicting-price-157}.} However, LSTM is unaware of these situations. Instead, HNN captures this signal and predicts that the price would rise in the future. And \myfigref{fig:chapter5:predicting-price-158-price} proves the predictions. However, RMSE cannot reflect this situation well, and that is why the RMSE of HNN is higher than that of LSTM when $\Delta b_n$ is larger ($\Delta b_n \ge  26.2$ in the \myfigref{fig:chapter5:predicting-price}).

\begin{figure}[htb!]
    \centering
    \subfloat[Native]{
    \includegraphics[height=4cm,width=\textwidth/3]{thesis/img/predictions/baseline-rmse.png}
        \label{fig:chapter5:predicting-price-baseline}

    }
     \subfloat[LSTM]{
    \includegraphics[height=4cm,width=\textwidth/3]{thesis/img/predictions/lstm-rmse.png}
        \label{fig:chapter5:predicting-price-lstm}
    
    }
     \subfloat[HNN]{
    \includegraphics[height=4cm,width=\textwidth/3]{thesis/img/predictions/hnn-rmse.png}
            \label{fig:chapter5:predicting-price-hnn}

    }
    \caption[The RMSE for different methods.]{The RMSE for different methods. The x-axis is $\Delta p$, the y-axis is $\Delta b$, and the z-axis is RMSE.}
    \label{fig:chapter5:predicting-price}
\end{figure}


\begin{figure}[ht!]
    \centering
    \subfloat[]{
    \includegraphics[height=4cm,width=\textwidth/2]{thesis/img/price-predictions/156.pdf}
        \label{fig:chapter5:predicting-price-156}

    }
     \subfloat[]{
    \includegraphics[height=4cm,width=\textwidth/2]{thesis/img/price-predictions/157.pdf}
        \label{fig:chapter5:predicting-price-157}
    
    }

    \caption[The dynamics of aggregated agents extracted from the simulation.]{\myupdate{Two consecutive} dynamics of aggregated agents extracted from the simulation. The price changes from $p_{i-1}$ to $p_i$ in \myfigref{fig:chapter5:predicting-price-156} and jumps from $p_i$ to $p_{i+1}$ in \myfigref{fig:chapter5:predicting-price-157}. \myfigref{fig:chapter5:predicting-price-156} and \myfigref{fig:chapter5:predicting-price-157} are corresponding to \myfigref{fig:chapter5:predicting-price-157-price} and \myfigref{fig:chapter5:predicting-price-158-price} respectively. \myupdate{The blue curve (dynamics generated by \myupdate{actual scenario}) is the dynamics of aggregated agents that took place in simulation. The orange one (dynamics generated by \myupdate{potential scenario}) is that we want to inspect what the dynamics would be if external agents take the opposite action at the same time steps, i.e., if the blue curve is resulted in by external agents buy the stocks from market, the orange curve is resulted in by the external agents sell the stock to market correspondingly.}}
    \label{fig:chapter5:price-predictions}
\end{figure}
\begin{figure}[ht!]
    \centering

     \subfloat[]{
    \includegraphics[height=4cm,width=\textwidth]{thesis/img/price-predictions/157-price.pdf}
        \label{fig:chapter5:predicting-price-157-price}
    }
    \hfill
    
    \subfloat[]{
    \hbox{\hspace{0.7em}}\includegraphics[height=4cm,width=\textwidth]{thesis/img/price-predictions/158-price.pdf}\label{fig:chapter5:predicting-price-158-price}
    }
    \caption[The consecutive predicted prices given by HNN and LSTM networks.]{The consecutive predicted prices given by HNN and LSTM networks. \myfigref{fig:chapter5:predicting-price-157-price} and \myfigref{fig:chapter5:predicting-price-158-price} are corresponding to \myfigref{fig:chapter5:predicting-price-156} and \myfigref{fig:chapter5:predicting-price-157} respectively. The blue horizontal line is the ground-truth price, the red horizontal one is the price predicted by LSTM, the cyan curve is the price predicted by HNN 100 times, and the green horizontal line is the average of price predicted by HNN.}
    \label{fig:chapter5:predicting-price-2}
\end{figure}