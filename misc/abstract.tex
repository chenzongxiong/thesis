\thispagestyle{empty}
\vspace*{1.0cm}

\begin{center}
    % \textbf{Hysteretic neural networks - Abstract}
    \textbf{Abstract}
\end{center}

\vspace*{0.5cm}

\noindent
\textit{Hysteresis} is defined as a \textit{rate independent} process with local \textit{memory}. A wide class of hysteretic systems is formed by an elementary block, \textit{Preisach operator}. In this thesis, we approximate this kind of hysteretic process by neural networks.
RNNs can approximate processes with memory, but standard architectures such as LSTM fail to learn the hysteretic relation from inputs and outputs.
Hence, we develop a new network architecture, so-called hysteretic neural networks (HNN), which is a \myupdate{superposition} of \textit{nonlinear plays}. We compare the RMSE between HNN and LSTM networks, and it shows that HNN is significantly better than LSTM networks. 
Furthermore, we generalize a financial market model based on \citep{dima2014}.
\myupdate{It also reveals HNN can achieve better performance than LSTM networks with fewer parameters.} 
